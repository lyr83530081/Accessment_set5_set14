{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb55139",
   "metadata": {},
   "source": [
    "# STEP 2: Define Evaluation Metrics\n",
    "* PSNR\n",
    "* SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac5db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plt_img(input_array, model_x, w, h):\n",
    "    input_img = input_array[0]\n",
    "    input_img = input_img.transpose((1, 2, 0))\n",
    "    \n",
    "    if model_x == \"SRCNN\":\n",
    "        plt.imshow(input_img)\n",
    "    elif model_x == \"ESPCN\":\n",
    "        input_img_resize = cv2.resize(input_img, (w, h), interpolation = cv.INTER_AREA)\n",
    "        plt.imshow(input_img_resize)\n",
    "    plt.show()\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean( (original/255. - compressed/255.) ** 2 )\n",
    "    if mse < 1.0e-10: return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "def calculate_PSNR(original_batch, compressed_batch, batch_size):\n",
    "    PSNR_TOTAL = 0\n",
    "    for num in range(batch_size):\n",
    "        psnr = PSNR(original_batch[num], compressed_batch[num])\n",
    "        PSNR_TOTAL = PSNR_TOTAL + psnr\n",
    "    return PSNR_TOTAL\n",
    "\n",
    "def SSIM(img1, img2):\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "def calculate_SSIM(img1, img2):\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    if img1.ndim == 2:\n",
    "        return ssim(img1, img2)\n",
    "    elif img1.ndim == 3:\n",
    "        if img1.shape[2] == 3:\n",
    "            ssims = []\n",
    "            for i in range(3):\n",
    "                ssims.append(ssim(img1, img2))\n",
    "            return np.array(ssims).mean()\n",
    "        elif img1.shape[2] == 1:\n",
    "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "    else:\n",
    "        raise ValueError('Wrong input image dimensions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c7e6a",
   "metadata": {},
   "source": [
    "# STEP 3: Design Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff13be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DIV2K_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, width, height, scale, path_to_imgs, model_x, transform = None):\n",
    "        self.model_x = model_x\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.scale = scale\n",
    "        self.path_to_imgs = path_to_imgs\n",
    "        self.length = len(os.listdir(path_to_imgs))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Interpolation: INTER_CUBIC, INTER_NEAREST, INTER_LINEAR, INTER_LANCZOS4, 【INTER_AREA】\n",
    "        img = cv.imread(self.path_to_imgs + os.listdir(self.path_to_imgs)[index])\n",
    "        img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        h, w, c = img_rgb.shape\n",
    "        if (h > w):\n",
    "            img_rgb = img_rgb.transpose((1,0,2))\n",
    "        \n",
    "        img_hr   = cv.resize(img_rgb,   (self.width             , self.height             ), interpolation = cv.INTER_AREA)\n",
    "        img_lr_1 = cv.resize(img_hr ,   (self.width //self.scale, self.height //self.scale), interpolation = cv.INTER_AREA)\n",
    "        img_lr_2 = cv.resize(img_lr_1 , (self.width             , self.height             ), interpolation = cv.INTER_AREA)\n",
    "        if self.transform and self.model_x == \"SRCNN\":\n",
    "            img_lr_tensor = self.transform(img_lr_2)\n",
    "            img_hr_tensor = self.transform(img_hr)\n",
    "        \n",
    "        elif self.transform and self.model_x == \"ESPCN\":\n",
    "            img_lr_tensor = self.transform(img_lr_1)\n",
    "            img_hr_tensor = self.transform(img_hr)\n",
    "            \n",
    "        return (img_lr_tensor, img_hr_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b146b",
   "metadata": {},
   "source": [
    "# STEP 4: Define Model ==> SRCNN\n",
    "* Github Repo Link: https://github.com/yjn870/SRCNN-pytorch\n",
    "* Difference:\n",
    "    1. Added the zero padding\n",
    "    2. Used the Adam instead of the SGD\n",
    "    3. Removed the weights initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a829853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels = 3):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size = 9, padding = 9 // 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size = 5, padding = 5 // 2)\n",
    "        self.conv3 = nn.Conv2d(32, num_channels, kernel_size = 5, padding = 5 // 2)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ESPCN(nn.Module):\n",
    "    def __init__(self, scale_factor, num_channels=2):\n",
    "        super(ESPCN, self).__init__()\n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 64, kernel_size=5, padding=5//2),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=3//2),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.last_part = nn.Sequential(\n",
    "            nn.Conv2d(32, num_channels * (scale_factor ** 2), kernel_size=3, padding=3 // 2),\n",
    "            nn.PixelShuffle(scale_factor)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m.in_channels == 32:\n",
    "                    nn.init.normal_(m.weight.data, mean=0.0, std=0.001)\n",
    "                    nn.init.zeros_(m.bias.data)\n",
    "                else:\n",
    "                    nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
    "                    nn.init.zeros_(m.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_part(x)\n",
    "        x = self.last_part(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe26a4",
   "metadata": {},
   "source": [
    "# STEP 5: Summerize Model & Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbd59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "width, height = 2000, 1600\n",
    "scale = 4\n",
    "path_to_train_imgs = \"../dataset/Flickr2K/\"\n",
    "path_to_valid_imgs = \"../dataset/DIV2K/DIV2K_valid_HR/\"\n",
    "trans_train = transforms.Compose([transforms.ToTensor()])\n",
    "trans_valid = transforms.Compose([transforms.ToTensor()]) \n",
    "batch_size = 6\n",
    "model_x = \"ESPCN\"\n",
    "\n",
    "Train_Dataset = DIV2K_Dataset(width = width, height = height, scale = scale, path_to_imgs = path_to_train_imgs, model_x = model_x, transform = trans_train)\n",
    "Train_Dataloader = DataLoader(Train_Dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "\n",
    "Valid_Dataset = DIV2K_Dataset(width = width, height = height, scale = scale, path_to_imgs = path_to_valid_imgs, model_x = model_x, transform = trans_valid)\n",
    "Valid_Dataloader = DataLoader(Valid_Dataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "\n",
    "if False and model_x == \"SRCNN\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SRCNN(num_channels = 3)\n",
    "    model = model.to(device)\n",
    "    summary(model, input_size = (3, width, height))  \n",
    "elif False and model_x == \"ESPCN\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ESPCN(scale_factor = scale, num_channels = 3)\n",
    "    model = model.to(device)\n",
    "    summary(model, input_size = (3, width//scale, height//scale))\n",
    "    # Estimated total size (MB): 220.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68a6d4",
   "metadata": {},
   "source": [
    "# STEP 6: Set Hyper Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4604342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if model_x == \"SRCNN\":\n",
    "    model = SRCNN(num_channels = 3).to(device)\n",
    "elif model_x == \"ESPCN\":\n",
    "    model = ESPCN(scale_factor = scale, num_channels = 3).to(device)\n",
    "    \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ccd48",
   "metadata": {},
   "source": [
    "# STEP 7: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                 | 2/525 [00:01<07:25,  1.17it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "#load weight\n",
    "def load_checkpoint(model, checkpoint_PATH, optimizer):\n",
    "    model_CKPT = torch.load(checkpoint_PATH)\n",
    "    model.load_state_dict(model_CKPT['model_state_dict'])\n",
    "    print('loading checkpoint!')\n",
    "    optimizer.load_state_dict(model_CKPT['optimizer_state_dict'])\n",
    "    return model, optimizer\n",
    "\n",
    "#checkpoint_PATH = 'checkpoints/epoch2_0.0003274347081536516_12.9556.pth'\n",
    "#model,optimizer = load_checkpoint(model, checkpoint_PATH, optimizer)\n",
    "\n",
    "probe_number =  80\n",
    "loss_list = []\n",
    "train_psnr_before_list = []\n",
    "train_psnr_after_list = []\n",
    "valid_psnr_before_list = []\n",
    "valid_psnr_after_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_psnr_before = 0\n",
    "    running_psnr_after = 0\n",
    "    inner_epoch_count = 0\n",
    "    train_total = 0\n",
    "    for data in tqdm(Train_Dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #print(inputs.shape)\n",
    "        preds = model(inputs).clamp(0.0, 1.0)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        if model_x == \"SRCNN\":\n",
    "            psnr_before= calculate_PSNR(inputs.data.cpu().numpy(), labels.data.cpu().numpy(), labels.size(0))\n",
    "            running_psnr_before = running_psnr_before + psnr_before\n",
    "\n",
    "        psnr_after = calculate_PSNR( preds.data.cpu().numpy(), labels.data.cpu().numpy(), labels.size(0))\n",
    "        running_psnr_after  = running_psnr_after  + psnr_after\n",
    "\n",
    "        running_loss = running_loss + loss.item()\n",
    "        \n",
    "        train_total = train_total + labels.size(0)\n",
    "        inner_epoch_count = inner_epoch_count + 1\n",
    "        if inner_epoch_count % probe_number == probe_number - 1:\n",
    "            for ele in [inputs.data.cpu().numpy(), preds.data.cpu().numpy(), labels.data.cpu().numpy()]:\n",
    "                plt_img(ele, model_x,width, height)\n",
    "            loss_list.append(running_loss/train_total)\n",
    "            if model_x == \"SRCNN\":\n",
    "                train_psnr_before_list.append(running_psnr_before/train_total)\n",
    "            \n",
    "            train_psnr_after_list.append(running_psnr_after/train_total)\n",
    "            print(f\"Before: {round(running_psnr_before/train_total, 4)}, After: {round(running_psnr_after/train_total, 4)}, Diff: {(round((running_psnr_after - running_psnr_before)/train_total, 4))}, Loss: {round(running_loss/train_total, 5)}\")\n",
    "            train_total = 0\n",
    "            running_psnr_before = 0\n",
    "            running_psnr_after = 0\n",
    "            running_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    running_psnr_before = 0\n",
    "    running_psnr_after = 0\n",
    "    valid_total = 0\n",
    "    for data in tqdm(Valid_Dataloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        valid_total = valid_total + labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs).clamp(0.0, 1.0)\n",
    "                \n",
    "        if model_x == \"SRCNN\":\n",
    "            psnr_before= calculate_PSNR(inputs.data.cpu().numpy(), labels.data.cpu().numpy(), labels.size(0))\n",
    "            valid_psnr_before_list.append(psnr_before/labels.size(0))\n",
    "            running_psnr_before = running_psnr_before + psnr_before/labels.size(0)\n",
    "        \n",
    "        psnr_after = calculate_PSNR( preds.data.cpu().numpy(), labels.data.cpu().numpy(), labels.size(0))\n",
    "        valid_psnr_after_list.append(psnr_after/labels.size(0))\n",
    "        running_psnr_after = running_psnr_after + psnr_after/labels.size(0)\n",
    "    torch.save({'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),}, \n",
    "               os.path.join('./checkpoints', 'epoch{0}_{1}_{2}.pth'.format(epoch,running_loss/train_total,round(running_psnr_after/valid_total, 4))))   \n",
    "\n",
    "    print(f\"Before: {round(running_psnr_before/valid_total, 4)}, After: {round(running_psnr_after/valid_total, 4)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992cdbb0",
   "metadata": {},
   "source": [
    "# STEP 8: Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb941e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_psnr_before_list)\n",
    "plt.plot(train_psnr_after_list)\n",
    "plt.show()\n",
    "\n",
    "#plt.plot(valid_psnr_before_list)\n",
    "plt.plot(valid_psnr_after_list)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f1649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, channels):\n",
    "    super(ResidualBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(channels, channels, kernel_size = 3, padding = 1)\n",
    "    self.bn1 = nn.BatchNorm2d(channels)\n",
    "    self.prelu = nn.PReLU()\n",
    "    self.conv2 = nn.Conv2d(channels, channels, kernel_size = 3, padding = 1)\n",
    "    self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    residual = self.conv1(x)\n",
    "    residual = self.bn1(residual)\n",
    "    residual = self.prelu(residual)\n",
    "    residual = self.conv2(residual)\n",
    "    residual = self.bn2(residual)\n",
    "\n",
    "    return x + residual\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "  def __init__(self, in_channels, up_scale):\n",
    "    super(UpsampleBlock, self).__init__()\n",
    "    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size = 3, padding = 1)\n",
    "    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
    "    self.prelu = nn.PReLU()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.conv(x)\n",
    "    x = self.pixel_shuffle(x)\n",
    "    x = self.prelu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef4c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.vgg import vgg16\n",
    "\n",
    "class GeneratorLoss(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(GeneratorLoss, self).__init__()\n",
    "    vgg = vgg16(pretrained = True)\n",
    "    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
    "    for param in loss_network.parameters():\n",
    "      param.requires_grad = False\n",
    "    self.loss_network = loss_network\n",
    "    self.mse_loss = nn.MSELoss()\n",
    "    self.tv_loss = TVLoss()\n",
    "\n",
    "  def forward(self, out_labels, out_images, target_images):\n",
    "    # Adversarial Loss\n",
    "    adversarial_loss = torch.mean(1 - out_labels)\n",
    "    # Perception Loss\n",
    "    perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "    # Image Loss\n",
    "    image_loss = self.mse_loss(out_images, target_images)\n",
    "    # TV Loss\n",
    "    tv_loss = self.tv_loss(out_images)\n",
    "    return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
    "\n",
    "class TVLoss(nn.Module):\n",
    "  def __init__(self, tv_loss_weight = 1):\n",
    "    super(TVLoss, self).__init__()\n",
    "    self.tv_loss_weight = tv_loss_weight\n",
    "  \n",
    "  def forward(self, x):\n",
    "    batch_size = x.size()[0]\n",
    "    h_x = x.size()[2]\n",
    "    w_x = x.size()[3]\n",
    "    count_h = self.tensor_size(x[:, :, 1:, :])\n",
    "    count_w = self.tensor_size(x[:, :, :, 1:])\n",
    "    h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
    "    w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
    "    return self.tv_loss_weight * 2 * (h_tv/count_h + w_tv/count_w)/batch_size\n",
    "\n",
    "  @staticmethod\n",
    "  def tensor_size(t):\n",
    "    return t.size()[1] * t.size()[2] * t.size()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a26d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, scale_factor):\n",
    "    upsample_block_num = int(math.log(scale_factor, 2))\n",
    "\n",
    "    super(Generator, self).__init__()\n",
    "    self.block1 = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size = 9, padding = 4),\n",
    "        nn.PReLU()\n",
    "    )\n",
    "    self.block2 = ResidualBlock(64)\n",
    "    self.block3 = ResidualBlock(64)\n",
    "    self.block4 = ResidualBlock(64)\n",
    "    self.block5 = ResidualBlock(64)\n",
    "    self.block6 = ResidualBlock(64)\n",
    "    self.block7 = nn.Sequential(\n",
    "        nn.Conv2d(64, 64, kernel_size = 3, padding = 1),\n",
    "        nn.BatchNorm2d(64)\n",
    "    )\n",
    "    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n",
    "    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
    "    self.block8 = nn.Sequential(*block8)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    block1 = self.block1(x)\n",
    "    block2 = self.block2(block1)\n",
    "    block3 = self.block3(block2)\n",
    "    block4 = self.block4(block3)\n",
    "    block5 = self.block5(block4)\n",
    "    block6 = self.block6(block5)\n",
    "    block7 = self.block7(block6)\n",
    "    block8 = self.block8(block1 + block7)\n",
    "\n",
    "    return (torch.tanh(block8) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7060b42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set5: img_001.png\n",
      "      RESIZE PSNR:35.13421450709595 SSIM:0.9079971135147644\n",
      "       SRCNN PSNR:37.5565918757877 SSIM:0.951618363731478\n",
      "       ESPCN PSNR:36.007899790392614 SSIM:0.9483355041247924\n",
      "       ESPCN PSNR:30.920143944397363 SSIM:0.9036492704549086\n",
      "Set5: img_002.png\n",
      "      RESIZE PSNR:35.616507274301796 SSIM:0.922528782375049\n",
      "       SRCNN PSNR:36.77142214750398 SSIM:0.9436271011660144\n",
      "       ESPCN PSNR:35.53241824326744 SSIM:0.9235352180666399\n",
      "       ESPCN PSNR:30.56701317120716 SSIM:0.8688554103046215\n",
      "Set5: img_003.png\n",
      "      RESIZE PSNR:28.82309668871239 SSIM:0.8787062056190916\n",
      "       SRCNN PSNR:30.909944167358454 SSIM:0.9193094153735953\n",
      "       ESPCN PSNR:30.32859914330903 SSIM:0.9061033391940184\n",
      "       ESPCN PSNR:27.156334891586592 SSIM:0.8654922418165132\n",
      "Set5: img_004.png\n",
      "      RESIZE PSNR:35.1741416578918 SSIM:0.8805180983223974\n",
      "       SRCNN PSNR:36.83169231990497 SSIM:0.925014151440218\n",
      "       ESPCN PSNR:34.76954145019376 SSIM:0.8929336612114488\n",
      "       ESPCN PSNR:31.65393596440628 SSIM:0.860541872855097\n",
      "Set5: img_005.png\n",
      "      RESIZE PSNR:32.98638831466069 SSIM:0.9089302676397771\n",
      "       SRCNN PSNR:34.459549245108356 SSIM:0.938009190729922\n",
      "       ESPCN PSNR:34.279343353744636 SSIM:0.9334310504088538\n",
      "       ESPCN PSNR:30.298841309911882 SSIM:0.8933467507070698\n",
      "Average:\n",
      "     RESIZE PSNR:33.546869688532524 SSIM:0.8997360934942158\n",
      "     RESIZE PSNR:35.30583995113269 SSIM:0.9355156444882455\n",
      "     RESIZE PSNR:34.1835603961815 SSIM:0.9208677546011508\n",
      "     RESIZE PSNR:30.119253856301857 SSIM:0.8783771092276421\n",
      "======================================================================\n",
      "Set5: img_001.png\n",
      "      RESIZE PSNR:26.202054133690233 SSIM:0.7853344281055086\n",
      "       SRCNN PSNR:26.143783106623623 SSIM:0.7594390800268155\n",
      "       ESPCN PSNR:25.05258382869103 SSIM:0.6858857334542726\n",
      "       ESPCN PSNR:24.082890996590514 SSIM:0.6324882870389654\n",
      "Set5: img_002.png\n",
      "      RESIZE PSNR:27.450165686394858 SSIM:0.8003500253299598\n",
      "       SRCNN PSNR:29.824291273163176 SSIM:0.8792834715467466\n",
      "       ESPCN PSNR:29.367376264372368 SSIM:0.8698225174848631\n",
      "       ESPCN PSNR:26.73856144981601 SSIM:0.7943855418269673\n",
      "Set5: img_003.png\n",
      "      RESIZE PSNR:28.018242426788532 SSIM:0.7543495768085979\n",
      "       SRCNN PSNR:30.449600237714215 SSIM:0.8469947748144208\n",
      "       ESPCN PSNR:30.230228999956363 SSIM:0.8458192962239807\n",
      "       ESPCN PSNR:27.875757774322928 SSIM:0.7697876327272316\n",
      "Set5: img_004.png\n",
      "      RESIZE PSNR:31.841742627889783 SSIM:0.8402287906556392\n",
      "       SRCNN PSNR:33.62371823098232 SSIM:0.895854106162717\n",
      "       ESPCN PSNR:33.43941852702287 SSIM:0.8922426024335354\n",
      "       ESPCN PSNR:30.215488478378248 SSIM:0.8458450513229417\n",
      "Set5: img_005.png\n",
      "      RESIZE PSNR:27.886194880618362 SSIM:0.8167122182766229\n",
      "       SRCNN PSNR:29.686302293944383 SSIM:0.8741606314394741\n",
      "       ESPCN PSNR:29.17141215554433 SSIM:0.8606165374672371\n",
      "       ESPCN PSNR:26.83032637789847 SSIM:0.8125614537034643\n",
      "Set5: img_006.png\n",
      "      RESIZE PSNR:35.33676627734862 SSIM:0.8843472836504266\n",
      "       SRCNN PSNR:36.91969776777108 SSIM:0.9263645290738558\n",
      "       ESPCN PSNR:34.82077639991549 SSIM:0.8943715601350164\n",
      "       ESPCN PSNR:31.673662719454036 SSIM:0.8621147675922238\n",
      "Set5: img_007.png\n",
      "      RESIZE PSNR:32.772011198937875 SSIM:0.9302190262293358\n",
      "       SRCNN PSNR:31.31870014540962 SSIM:0.9028191422486093\n",
      "       ESPCN PSNR:30.453895035902164 SSIM:0.8749958629965621\n",
      "       ESPCN PSNR:27.85434304636344 SSIM:0.8422332366971853\n",
      "Set5: img_008.png\n",
      "      RESIZE PSNR:33.348517255431325 SSIM:0.9252491471405007\n",
      "       SRCNN PSNR:34.81364493882391 SSIM:0.9496001732172573\n",
      "       ESPCN PSNR:34.150032211023046 SSIM:0.9450102959569439\n",
      "       ESPCN PSNR:30.929695689446966 SSIM:0.9076590843036749\n",
      "Set5: img_009.png\n",
      "      RESIZE PSNR:33.17891613090389 SSIM:0.8619814102094326\n",
      "       SRCNN PSNR:34.96988781414136 SSIM:0.9059258246689537\n",
      "       ESPCN PSNR:33.35957264247959 SSIM:0.8799345307324163\n",
      "       ESPCN PSNR:28.890677486438612 SSIM:0.8423281556676834\n",
      "Set5: img_010.png\n",
      "      RESIZE PSNR:29.40814634245589 SSIM:0.815752437617752\n",
      "       SRCNN PSNR:31.870472083104428 SSIM:0.8820278926696069\n",
      "       ESPCN PSNR:31.710263574822854 SSIM:0.8791248976930768\n",
      "       ESPCN PSNR:29.421979717602326 SSIM:0.8076829901969403\n",
      "Set5: img_011.png\n",
      "      RESIZE PSNR:30.466953877117263 SSIM:0.9079007172562132\n",
      "       SRCNN PSNR:34.78086457062623 SSIM:0.9582129811649004\n",
      "       ESPCN PSNR:33.568033481402274 SSIM:0.9497247307128763\n",
      "       ESPCN PSNR:29.783377942773733 SSIM:0.908445009769655\n",
      "Set5: img_012.png\n",
      "      RESIZE PSNR:32.281966804629704 SSIM:0.8523224698536603\n",
      "       SRCNN PSNR:33.298290879475935 SSIM:0.8776708978581734\n",
      "       ESPCN PSNR:31.04028834627719 SSIM:0.8506273856533798\n",
      "       ESPCN PSNR:27.18378965210235 SSIM:0.7879928852244403\n",
      "Set5: img_013.png\n",
      "      RESIZE PSNR:25.625496959217656 SSIM:0.9102062642091885\n",
      "       SRCNN PSNR:29.699956942982478 SSIM:0.9488566132345243\n",
      "       ESPCN PSNR:27.85287523221011 SSIM:0.9344141877967179\n",
      "       ESPCN PSNR:26.088140038493858 SSIM:0.879382464404775\n",
      "Set5: img_014.png\n",
      "      RESIZE PSNR:28.796160748986487 SSIM:0.8212617849723775\n",
      "       SRCNN PSNR:31.914707698516047 SSIM:0.9018382900848374\n",
      "       ESPCN PSNR:31.794601188083533 SSIM:0.9013436180397327\n",
      "       ESPCN PSNR:27.492728517273065 SSIM:0.8253234729004533\n",
      "Average:\n",
      "     RESIZE PSNR:30.186666810743606 SSIM:0.8504439700225154\n",
      "     RESIZE PSNR:32.093851284519914 SSIM:0.8935034577293495\n",
      "     RESIZE PSNR:31.143668420550235 SSIM:0.8759952683414722\n",
      "     RESIZE PSNR:28.21867284906818 SSIM:0.8227307166697574\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import PIL.Image as pil_image\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from skimage.metrics import structural_similarity as ssim_cal\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def img_preprocess(image_file):\n",
    "    img = cv.imread(image_file)\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    h, w, c = img_rgb.shape\n",
    "    width, height = 2000, 1600\n",
    "\n",
    "    if (h > w):\n",
    "        img_rgb = img_rgb.transpose((1,0,2))\n",
    "    img_hr   = cv.resize(img_rgb,   (width             , height             ), interpolation = cv.INTER_AREA)\n",
    "    img_lr_1 = cv.resize(img_hr ,   (width //scale, height //scale), interpolation = cv.INTER_AREA)\n",
    "    img_lr_2 = cv.resize(img_lr_1 , (width             , height             ), interpolation = cv.INTER_AREA)\n",
    "    #img_hr   = cv.resize(img_rgb,   (width             , height             ), interpolation = cv.INTER_LINEAR)\n",
    "    #img_lr_1 = cv.resize(img_hr ,   (width //scale, height //scale), interpolation = cv.INTER_LINEAR)\n",
    "    #img_lr_2 = cv.resize(img_lr_1 , (width             , height             ), interpolation = cv.INTER_LINEAR)\n",
    "    image_in = transforms.ToTensor()(img_lr_2).unsqueeze(0).to(device)\n",
    "    image_lr = transforms.ToTensor()(img_lr_1).unsqueeze(0).to(device)\n",
    "    image_hr = transforms.ToTensor()(img_hr).unsqueeze(0).to(device)\n",
    "    return image_in,image_lr,image_hr\n",
    "\n",
    "scale = 4\n",
    "model_SRCNN = SRCNN(num_channels = 3).to(device)\n",
    "model_ESPCN = ESPCN(scale_factor = scale, num_channels = 3).to(device)\n",
    "model_SRGAN = Generator(scale).to(device)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "#load SRCNN checkpoint\n",
    "checkpoint_SRCNN = 'checkpoints/epoch9_0.00033620840335953913_13.0112.pth'\n",
    "model_CKPT_SRCNN = torch.load(checkpoint_SRCNN)\n",
    "model_SRCNN.load_state_dict(model_CKPT_SRCNN['model_state_dict'])\n",
    "model_SRCNN.eval()\n",
    "#load ESPCN checkpoint\n",
    "checkpoint_ESPCN = 'checkpoints/epoch9_0.000404924631030077_12.8325.pth'\n",
    "model_CKPT_ESPCN = torch.load(checkpoint_ESPCN)\n",
    "model_ESPCN.load_state_dict(model_CKPT_ESPCN['model_state_dict'])\n",
    "model_ESPCN.eval()\n",
    "#load SRGAN checkpoint\n",
    "checkpoint_SRGAN = '../epochs/netG_epoch_4_13.pth'\n",
    "model_CKPT_SRGAN = torch.load(checkpoint_SRGAN)\n",
    "model_SRGAN.load_state_dict(model_CKPT_SRGAN)\n",
    "model_SRGAN.eval()\n",
    "\n",
    "#image_file = '../dataset/set5/img_001.png'\n",
    "img_path_set5 = '../dataset/set5'\n",
    "f1 = os.listdir(img_path_set5)\n",
    "ssim_r_set5 = 0\n",
    "psnr_r_set5 = 0\n",
    "ssim_srcnn_set5 = 0\n",
    "psnr_srcnn_set5 = 0\n",
    "ssim_espcn_set5 = 0\n",
    "psnr_espcn_set5 = 0\n",
    "ssim_srgan_set5 = 0\n",
    "psnr_srgan_set5 = 0\n",
    "for image_file in f1:\n",
    "    \n",
    "    image_in,image_lr,image_hr = img_preprocess(img_path_set5+'/'+image_file)\n",
    "    \n",
    "    ####RESIZE ONLY\n",
    "    psnr_resize = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*image_in.squeeze(0).cpu().numpy().transpose([1, 2, 0]))\n",
    "    ssim_resize = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*image_in.squeeze(0).cpu().numpy().transpose([1, 2, 0]))\n",
    "    psnr_r_set5 += psnr_resize\n",
    "    ssim_r_set5 += ssim_resize\n",
    "    ####SRCNN\n",
    "    result_SRCNN = model_SRCNN(image_in).clamp(0.0, 1.0)\n",
    "    psnr_srcnn = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRCNN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    ssim_srcnn = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRCNN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    psnr_srcnn_set5 += psnr_srcnn\n",
    "    ssim_srcnn_set5 += ssim_srcnn\n",
    "    ####ESPCN\n",
    "    result_ESPCN = model_ESPCN(image_lr).clamp(0.0, 1.0)\n",
    "    psnr_espcn = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_ESPCN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    ssim_espcn = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_ESPCN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    psnr_espcn_set5 += psnr_espcn\n",
    "    ssim_espcn_set5 += ssim_espcn\n",
    "    ####SRGAN\n",
    "    result_SRGAN = model_SRGAN(image_lr).clamp(0.0, 1.0)\n",
    "    psnr_srgan = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRGAN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    ssim_srgan = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRGAN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    psnr_srgan_set5 += psnr_srgan\n",
    "    ssim_srgan_set5 += ssim_srgan\n",
    "    \n",
    "    \n",
    "    print('Set5: '+image_file)\n",
    "    print('      RESIZE PSNR:'+str(psnr_resize)+' SSIM:'+str(ssim_resize))\n",
    "    print('       SRCNN PSNR:'+str(psnr_srcnn)+' SSIM:'+str(ssim_srcnn))\n",
    "    print('       ESPCN PSNR:'+str(psnr_espcn)+' SSIM:'+str(ssim_espcn))\n",
    "    print('       SRGAN PSNR:'+str(psnr_srgan)+' SSIM:'+str(ssim_srgan))\n",
    "print('Average:')\n",
    "print('     RESIZE PSNR:'+str(psnr_r_set5/5)+' SSIM:'+str(ssim_r_set5/5))\n",
    "print('      SRCNN PSNR:'+str(psnr_srcnn_set5/5)+' SSIM:'+str(ssim_srcnn_set5/5))\n",
    "print('      ESPCN PSNR:'+str(psnr_espcn_set5/5)+' SSIM:'+str(ssim_espcn_set5/5))\n",
    "print('      SRGAN PSNR:'+str(psnr_srgan_set5/5)+' SSIM:'+str(ssim_srgan_set5/5))\n",
    "    \n",
    "print('======================================================================')    \n",
    "img_path_set14 = '../dataset/set14'\n",
    "f2 = os.listdir(img_path_set14)\n",
    "ssim_r_set14 = 0\n",
    "psnr_r_set14 = 0\n",
    "ssim_srcnn_set14 = 0\n",
    "psnr_srcnn_set14 = 0\n",
    "ssim_espcn_set14 = 0\n",
    "psnr_espcn_set14 = 0\n",
    "ssim_srgan_set14 = 0\n",
    "psnr_srgan_set14 = 0\n",
    "for image_file in f2:\n",
    "    \n",
    "    image_in,image_lr,image_hr = img_preprocess(img_path_set14+'/'+image_file)\n",
    "    \n",
    "    ####RESIZE ONLY\n",
    "    psnr_resize = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*image_in.squeeze(0).cpu().numpy().transpose([1, 2, 0]))\n",
    "    ssim_resize = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*image_in.squeeze(0).cpu().numpy().transpose([1, 2, 0]))\n",
    "    psnr_r_set14 += psnr_resize\n",
    "    ssim_r_set14 += ssim_resize\n",
    "    ####SRCNN\n",
    "    result_SRCNN = model_SRCNN(image_in).clamp(0.0, 1.0)\n",
    "    psnr_srcnn = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRCNN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    ssim_srcnn = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRCNN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    psnr_srcnn_set14 += psnr_srcnn\n",
    "    ssim_srcnn_set14 += ssim_srcnn\n",
    "    ####ESPCN\n",
    "    result_ESPCN = model_ESPCN(image_lr).clamp(0.0, 1.0)\n",
    "    psnr_espcn = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_ESPCN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    ssim_espcn = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_ESPCN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    psnr_espcn_set14 += psnr_espcn\n",
    "    ssim_espcn_set14 += ssim_espcn\n",
    "    ####SRGAN\n",
    "    result_SRGAN = model_SRGAN(image_lr).clamp(0.0, 1.0)\n",
    "    psnr_srgan = PSNR(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRGAN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    ssim_srgan = SSIM(255*image_hr.squeeze(0).cpu().numpy().transpose([1, 2, 0]),255*result_SRGAN.squeeze(0).cpu().detach().numpy().transpose([1, 2, 0]))\n",
    "    psnr_srgan_set14 += psnr_srgan\n",
    "    ssim_srgan_set14 += ssim_srgan\n",
    "    \n",
    "    \n",
    "    print('Set5: '+image_file)\n",
    "    print('      RESIZE PSNR:'+str(psnr_resize)+' SSIM:'+str(ssim_resize))\n",
    "    print('       SRCNN PSNR:'+str(psnr_srcnn)+' SSIM:'+str(ssim_srcnn))\n",
    "    print('       ESPCN PSNR:'+str(psnr_espcn)+' SSIM:'+str(ssim_espcn))\n",
    "    print('       SRGAN PSNR:'+str(psnr_srgan)+' SSIM:'+str(ssim_srgan))\n",
    "print('Average:')\n",
    "print('     RESIZE PSNR:'+str(psnr_r_set14/14)+' SSIM:'+str(ssim_r_set14/14))\n",
    "print('      SRCNN PSNR:'+str(psnr_srcnn_set14/14)+' SSIM:'+str(ssim_srcnn_set14/14))\n",
    "print('      ESPCN PSNR:'+str(psnr_espcn_set14/14)+' SSIM:'+str(ssim_espcn_set14/14))\n",
    "print('      SRGAN PSNR:'+str(psnr_srgan_set14/14)+' SSIM:'+str(ssim_srgan_set14/14))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc320a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "91140e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- odict_items([('first_part', Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): Tanh()\n",
      "  (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Tanh()\n",
      ")), ('last_part', Sequential(\n",
      "  (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): PixelShuffle(upscale_factor=8)\n",
      "))])\n",
      "first_part\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): Tanh()\n",
      "  (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Tanh()\n",
      ")\n",
      "name first_part\n",
      "last_part\n",
      "Sequential(\n",
      "  (0): Conv2d(32, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): PixelShuffle(upscale_factor=8)\n",
      ")\n",
      "name last_part\n",
      "torch.Size([1, 32, 200, 250])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f5ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
